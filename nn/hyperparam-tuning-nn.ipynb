{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyperparameters for neural network using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import log_loss\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print('Accelerated Linear Algebra enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling...\n",
      "Converting...\n",
      "Finish.\n"
     ]
    }
   ],
   "source": [
    "# print('Loading...')\n",
    "# train = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\n",
    "train = pd.read_csv('input/train.csv')\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "print('Filling...')\n",
    "f_mean = train[features[1:]].mean()\n",
    "train = train[train.weight>0].reset_index(drop = True)\n",
    "train[features[1:]] = train[features[1:]].fillna(f_mean)\n",
    "train['action'] = (train.resp > 0).astype('int')\n",
    "\n",
    "print('Converting...')\n",
    "# train = train.to_pandas()\n",
    "f_mean = f_mean.values\n",
    "np.save('f_mean.npy', f_mean)\n",
    "\n",
    "print('Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n",
    "    \n",
    "    inp = tf.keras.layers.Input(shape = (num_columns, ))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "    \n",
    "#     print('hidden_units')\n",
    "#     print(hidden_units)\n",
    "    for i in range(len(hidden_units)): \n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n",
    "        \n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation('sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n",
    "                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise(params):\n",
    "    \n",
    "    n_splits = 5\n",
    "    batch_size = params['batch_size']\n",
    "    \n",
    "    #     hu = [params['hidden_unit_1'], \n",
    "    #           params['hidden_unit_2']]\n",
    "    \n",
    "    \n",
    "    ## At least 4 layers in best submission\n",
    "    hu = [params[f'hidden_unit_{n_layer}'] for n_layer in range(1, 5)]\n",
    "    \n",
    "    ## Dropout rates\n",
    "    \n",
    "\n",
    "    dropout_rates = [params[f'dropout_{n_}'] for n_ in range(0, 5)]\n",
    "    \n",
    "#     print('dropout_rates')\n",
    "#     print(dropout_rates)\n",
    "    \n",
    "#     print('hu')\n",
    "#     print(hu)\n",
    "    \n",
    "    for n_layer in range(5, 10):\n",
    "        if params[f'hidden_unit_{n_layer}'] != 0:\n",
    "            hu.append(params[f'hidden_unit_{n_layer}'])\n",
    "            dropout_rates.append(params[f'dropout_{n_layer}'])\n",
    "             \n",
    "        \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    \n",
    "#     print('params')\n",
    "#     print(params)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if params['hidden_unit_5'] != 0:\n",
    "#         hu.append(params['hidden_unit_5'])\n",
    "#         if params['hidden_unit_6'] !=0:\n",
    "#             hu.append(params['hidden_unit_6'])\n",
    "        \n",
    "    p = {'hidden_units': hu, \n",
    "         'dropout_rate': dropout_rates, \n",
    "         'label_smoothing': params['label_smoothing'],\n",
    "         'learning_rate': params['learning_rate']\n",
    "        }\n",
    "    \n",
    "#     print('p')\n",
    "#     print(p)\n",
    "    #     res_nn = train_targets.copy()\n",
    "    #     res_nn.loc[:, train_targets.columns] = 0\n",
    "    \n",
    "    oof = np.zeros(len(train['action']))\n",
    "    gkf = GroupKFold(n_splits = n_splits)\n",
    "    \n",
    "    val_scores = []\n",
    "    for fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n",
    "\n",
    "        ckp_path = f'JSModel_{fold}.hdf5'\n",
    "\n",
    "        X_tr, X_val = train.loc[tr, features].values, train.loc[te, features].values\n",
    "        y_tr, y_val = train.loc[tr, 'action'].values, train.loc[te, 'action'].values\n",
    "\n",
    "        with strategy.scope():\n",
    "            \n",
    "            model = create_model(num_columns= X_tr.shape[1], \n",
    "                                 num_labels = 1, \n",
    "                                 hidden_units=p['hidden_units'],\n",
    "                                 dropout_rates=p['dropout_rate'],\n",
    "                                 label_smoothing=p['label_smoothing'], \n",
    "                                 learning_rate=p['learning_rate'])\n",
    "            \n",
    "            # print(model.summary())\n",
    "\n",
    "        rlr = ReduceLROnPlateau(monitor='val_AUC', factor = 0.1, patience = 3, \n",
    "                                verbose = 0, epsilon = 1e-4, mode = 'max')\n",
    "\n",
    "        ckp = ModelCheckpoint(ckp_path, monitor = 'val_AUC', verbose = 0, \n",
    "                              save_best_only = True, save_weights_only = True, mode = 'max')\n",
    "        \n",
    "        es = EarlyStopping(monitor = 'val_AUC', min_delta = 0.0001, patience = 7, mode = 'max', \n",
    "                           baseline = None, restore_best_weights = True, verbose = 0)\n",
    "        \n",
    "        \n",
    "        # print(f\"X_tr: {X_tr.shape}, X_val: {X_val.shape}, y_tr: {y_tr.shape}, y_val:{y_val.shape}\")\n",
    "        \n",
    "        model.fit(X_tr, y_tr, validation_data = (X_val, y_val), \n",
    "                            epochs = 1000, batch_size = batch_size, \n",
    "                            callbacks = [rlr, ckp, es], verbose = 0)\n",
    "\n",
    "        # model.load_weights(f'model_{n}.hdf5')\n",
    "        # model.load_weights(ckp_path)\n",
    "\n",
    "        # res_nn.loc[te, train_targets.columns] += model.predict(x_val)\n",
    "        # print('Best Validation Loss:\\t', hist['val_loss'].min())\n",
    "        # print('-' * 50)\n",
    "        \n",
    "        \n",
    "        ## added from best submission\n",
    "        oof[te] += model.predict(X_val, batch_size = batch_size * 4).ravel()\n",
    "        score = roc_auc_score(y_val, oof[te])\n",
    "        # print(f'Fold {fold} ROC AUC:\\t', score)\n",
    "        val_scores.append(score)\n",
    "\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        rubbish = gc.collect()\n",
    "\n",
    "    \n",
    "    return 1 - np.mean(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "param_space = {'hidden_unit_1': hp.choice('hidden_unit_1', [1152, 1024,  896,  768,  640,  512,  384,  256,  128]), \n",
    "               'hidden_unit_2': hp.choice('hidden_unit_2', [1152, 1024,  896,  768,  640,  512,  384,  256,  128]), \n",
    "               'hidden_unit_3': hp.choice('hidden_unit_3', [1152, 1024,  896,  768,  640,  512,  384,  256,  128]), \n",
    "               'hidden_unit_4': hp.choice('hidden_unit_4', [1152, 1024,  896,  768,  640,  512,  384,  256,  128]), \n",
    "               'hidden_unit_5': hp.choice('hidden_unit_5', [0,  128,  256,  384,  512,  640,  768,  896, 1024, 1152]), \n",
    "               'hidden_unit_6': hp.choice('hidden_unit_6', [0,  128,  256,  384,  512,  640,  768,  896, 1024, 1152]), \n",
    "               'hidden_unit_7': hp.choice('hidden_unit_7', [0,  128,  256,  384,  512,  640,  768,  896, 1024, 1152]), \n",
    "               'hidden_unit_8': hp.choice('hidden_unit_8', [0,  128,  256,  384,  512,  640,  768,  896, 1024, 1152]), \n",
    "               'hidden_unit_9': hp.choice('hidden_unit_9', [0,  128,  256,  384,  512,  640,  768,  896, 1024, 1152]), \n",
    "               'dropout_0': hp.uniform('dropout_0', 0, 0.5),\n",
    "               'dropout_1': hp.uniform('dropout_1', 0, 0.5), \n",
    "               'dropout_2': hp.uniform('dropout_2', 0, 0.5), \n",
    "               'dropout_3': hp.uniform('dropout_3', 0, 0.5), \n",
    "               'dropout_4': hp.uniform('dropout_4', 0, 0.5), \n",
    "               'dropout_5': hp.uniform('dropout_5', 0, 0.5), \n",
    "               'dropout_6': hp.uniform('dropout_6', 0, 0.5), \n",
    "               'dropout_7': hp.uniform('dropout_7', 0, 0.5), \n",
    "               'dropout_8': hp.uniform('dropout_8', 0, 0.5), \n",
    "               'dropout_9': hp.uniform('dropout_9', 0, 0.5), \n",
    "                \n",
    "               'label_smoothing': hp.uniform('label_smoothing', 0, 0.1),\n",
    "               'learning_rate': hp.uniform('learning_rate', 0, 0.10 ), \n",
    "               'batch_size': hp.choice('batch_size', [4096, 4096*2])\n",
    "              }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "hopt = fmin(fn = optimise, \n",
    "            space = param_space, \n",
    "            algo = tpe.suggest, \n",
    "            max_evals = 10000, \n",
    "            timeout = 15 * 60 * 60, \n",
    "            trials = trials, \n",
    "           )\n",
    "\n",
    "print(hopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
